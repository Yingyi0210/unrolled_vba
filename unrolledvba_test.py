# -*- coding: utf-8 -*-
"""unrolledVBA_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OrEt42kDchfGflbPsi5dVoI7EEV8BIg9

# Preprocess

## Data
Use a method works for you

### Mount Google Drive (Use VBA Google Account)
"""


################  Set file directory.  ################


########################################################

from torch.utils.checkpoint import checkpoint
from tqdm import tqdm
from unroll_vba import *
import glob
import os
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
from args import Args
import random
# from autoencoder import Autoencoder
import matplotlib.pyplot as plt
from skimage.metrics import peak_signal_noise_ratio, structural_similarity
from dataset import *
from operators import *
import torchvision
import signal
from torchvision.models import vgg19
from skimage.metrics import structural_similarity as ssim_metric

class LossMeter:
    def __init__(self):
        self.reset()

    def reset(self):
        self.base_total = 0.0
        self.tv_total = 0.0
        self.per_total = 0.0
        self.count = 0

    def update(self, base, tv, per, n=1):
        self.base_total += base * n
        self.tv_total += tv * n
        self.per_total += per * n
        self.count += n

    def report(self):
        if self.count == 0:
            return 0, 0, 0
        return (self.base_total / self.count,
                self.tv_total / self.count,
                self.per_total / self.count)

# class TruncatedVGG19_UpToRelu34(nn.Module):
#     """
#     仅保留 VGG19 的前 8 个卷积（到 relu3_4），
#     用于快速计算感知特征；参数冻结、eval 模式。
#     支持 1ch/3ch 输入；1ch 会复制成 3ch 并做 ImageNet 归一化。
#     """
#     LAYER_NAME_BY_IDX = {
#         3: "relu1_2",
#         8: "relu2_2",
#         17: "relu3_4",
#     }
#
#     def __init__(self, return_layers=("relu1_2", "relu2_2", "relu3_4")):
#         super().__init__()
#         base = vgg19(pretrained=True).features
#         # 0..17 含：conv1_1, relu1_1, conv1_2, relu1_2, pool1,
#         #          conv2_1, relu2_1, conv2_2, relu2_2, pool2,
#         #          conv3_1, relu3_1, conv3_2, relu3_2, conv3_3, relu3_3, conv3_4, relu3_4
#         self.trunk = base[:18].eval()
#         for p in self.trunk.parameters():
#             p.requires_grad = False
#
#         # 记录需要返回的层（用 idx 对应）
#         name2idx = {v: k for k, v in self.LAYER_NAME_BY_IDX.items()}
#         self.return_indices = sorted([name2idx[n] for n in return_layers])
#
#         # ImageNet 归一化参数
#         mean = torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1)
#         std  = torch.tensor([0.229, 0.224, 0.225]).view(1,3,1,1)
#         self.register_buffer("mean", mean)
#         self.register_buffer("std", std)
#
#     @torch.no_grad()  # 仅用于预处理与 trunk 前传（不需要对 trunk 求梯度）
#     def _prep(self, x):
#         # x: [N,1,H,W] 或 [N,3,H,W]，值域 [0,1] / [0,255] 都可以（下方统一到 [0,1]）
#         if x.dtype != torch.float32:
#             x = x.float()
#         if x.max() > 1.5:  # 粗略判断是否为 0..255
#             x = x / 255.0
#         if x.shape[1] == 1:
#             x = x.repeat(1, 3, 1, 1)  # 单通道复制为伪RGB
#         # ImageNet 归一化
#         x = (x - self.mean) / self.std
#         return x
#
#     def forward(self, x):
#         x = self._prep(x)
#         feats = {}
#         for i, layer in enumerate(self.trunk):
#             x = layer(x)
#             if i in self.return_indices:
#                 feats[self.LAYER_NAME_BY_IDX[i]] = x
#         return feats

class VGGFeatureExtractor(nn.Module):
    """
    提取指定层的 VGG19 特征
    """
    def __init__(self, layers=("relu2_2", "relu3_4", "relu4_4")):
        super().__init__()

        vgg = vgg19(pretrained=True).features
        self.layers = layers

        # VGG 层名到 index 的映射
        name_to_idx = {
            "relu1_1": 1, "relu1_2": 3,
            "relu2_1": 6, "relu2_2": 8,
            "relu3_1": 11, "relu3_2": 13, "relu3_3": 15, "relu3_4": 17,
            "relu4_1": 20, "relu4_2": 22, "relu4_3": 24, "relu4_4": 26,
        }

        # 只保留到最深的那一层即可
        max_idx = max(name_to_idx[layer] for layer in layers)
        self.vgg = vgg[: max_idx + 1]
        self.vgg.eval()

        for param in self.vgg.parameters():
            param.requires_grad = False

        self.name_to_idx = name_to_idx

    def forward(self, x):
        """
        返回一个 dict:
        {
            "relu2_2": feature2,
            "relu3_4": feature3,
            "relu4_4": feature4
        }
        """
        outputs = {}
        for i, layer in enumerate(self.vgg):
            x = layer(x)
            for name in self.layers:
                if i == self.name_to_idx[name]:
                    outputs[name] = x
        return outputs

def compute_psnr(img1, img2):
    """计算两张 [0,1] 张量的 PSNR"""
    if isinstance(img1, np.ndarray):
        img1 = torch.from_numpy(img1)
    if isinstance(img2, np.ndarray):
        img2 = torch.from_numpy(img2)

        # 全部转到同一设备（这里统一到 CPU，且不跟踪梯度）
    img1 = img1.detach().to('cpu', dtype=torch.float32)
    img2 = img2.detach().to('cpu', dtype=torch.float32)
    mse = F.mse_loss(img1, img2)
    psnr = 10 * torch.log10(1.0 / mse)
    return psnr.item()

# hr_folder = r"D:\data\SR\DIV2K\DIV2K_train_HR_gray"
# dataset = SRDataset(hr_folder, patch_size=256, scale=4, noise_std=0.01, augment=True)
#dataset = dataset[0]
#print(dataset['x'].shape, dataset['y'].shape, dataset['Aty'].shape)

# Test autoencoder model
#model = Autoencoder()

#input_image = torch.randn(1, 1, 64, 64) # Batch size 1, 1 channel, 256x256 image
#output_image = model(input_image)
#print("Input size: ", input_image.size())
#print("Output size: ", output_image.size())

"""### Trainer"""

# def train_autoencoder(model, train_loader, num_epochs=10, learning_rate=0.001):
#     criterion = nn.MSELoss()
#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)
#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
#     model.to(device)
#
#     for epoch in range(num_epochs):
#         for data in train_loader:
#             y = data['y'].to(device)
#             x = data['x'].to(device)
#             # print("x size: ", x.size())
#             # print("Input size: ", y.size())
#             output = model(y)
#             loss = criterion(output, x)
#
#             optimizer.zero_grad()
#             loss.backward()
#             optimizer.step()
#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')
#
#
# transform = transforms.Compose([
#     transforms.ToPILImage(),
#     transforms.ToTensor(),
# ])

# dataset = InfraredDataset(hr_dir, lr_dir, transform=transform)
# Test test_data with 2 samples
# test_loader = DataLoader(dataset, batch_size=1, shuffle=True)
# autoencoder = Autoencoder()
#train_autoencoder(autoencoder, test_loader)

"""## Unroll VBA model

"""### VBA Trainer

class Trainer(object):

    def __init__(self, args):
        self.model = args.model
        self.device = args.device
        self.batch_size = args.batch_size
        self.lr = args.lr
        self.dataset = args.dataset
        self.loss = args.loss
        self.optimizer = args.optimizer
        self.num_workers = args.num_workers
        self.epochs = args.epochs
        self.log_interval = args.log_interval
        self.img_save_dir = args.imgdir
        # self.best_train_psnr = -1
        self.best_val_psnr = -1
        self.best_model_path = None
        self.model_dir = os.path.join(self.img_save_dir, "saved_models")
        os.makedirs(self.model_dir, exist_ok=True)
        os.makedirs(self.img_save_dir, exist_ok=True)

    def _get_model(self):
        if self.model == 'autoencoder':
            model = Autoencoder()
            model.to(self.device)
        elif self.model == 'UnrollVBA':
            scale = 4
            model = UnrollVBA(block_num=4, scale=scale, width=256, height=256)
            model.to(self.device)
            # for name, param in model.named_parameters():
            #     if param.requires_grad:
            #         print(name)
        else:
            raise NotImplementedError("Unsupported model: {}".format(self.model))
        return model


    def _get_dataset(self):
        if self.dataset == 'infrared':
            dataset = SRDataset(
                hr_root=r"C:\Users\vipuser\train_LR_HR_bicubic\HR_patches",
                lr_root=r"C:\Users\vipuser\train_LR_HR_bicubic\bicubicX4",
                scale=4)
            # train_dataset = SRDataset(
            #     hr_root=r"C:\Users\vipuser\train_LR_HR_5x5\train_LR_HR_5x5\HR_patches",
            #     lr_root=r"C:\Users\vipuser\train_LR_HR_5x5\train_LR_HR_5x5\LR",
            #     scale=4
            # )
            # val_dataset = SRDataset(
            #     hr_root=r"C:\Users\vipuser\val_LR_HR_5x5\HR_patches",
            #     lr_root=r"C:\Users\vipuser\val_LR_HR_5x5\LR",
            #     scale=4
            # )
        else:
            raise NotImplementedError("Unsupported dataset: {}".format(self.dataset))
        # return train_dataset, val_dataset
        return dataset

    def _get_train_val_datasets(self, val_ratio=0.2):
        dataset = self._get_dataset()
        total_len = len(dataset)
        val_len = int(total_len * val_ratio)
        train_len = total_len - val_len
        torch.manual_seed(42) # 固定数据集
        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_len, val_len])
        return train_dataset, val_dataset

    def _get_loss_func(self):
        def tv_loss_aniso(x, reduction='mean'):
            Dhx = x - torch.roll(x, shifts=1, dims=3)
            Dvx = x - torch.roll(x, shifts=1, dims=2)
            tv = torch.abs(Dhx) + torch.abs(Dvx)
            return tv.mean() if reduction == 'mean' else (tv.sum() if reduction == 'sum' else tv)

        def tv_loss_iso(x, eps=1e-3, reduction='mean'):
            Dhx = x - torch.roll(x, shifts=1, dims=3)
            Dvx = x - torch.roll(x, shifts=1, dims=2)
            tv = torch.sqrt(Dhx * Dhx + Dvx * Dvx + eps)
            return tv.mean() if reduction == 'mean' else (tv.sum() if reduction == 'sum' else tv)

        def tv_loss_charbonnier(x, eps=1e-6, reduction='mean'):
            Dhx = x - torch.roll(x, shifts=1, dims=3)
            Dvx = x - torch.roll(x, shifts=1, dims=2)
            tv = torch.sqrt(Dhx.pow(2) + Dvx.pow(2) + eps * eps)
            return tv.mean() if reduction == 'mean' else (tv.sum() if reduction == 'sum' else tv)

        loss_name = (self.loss or 'mse').lower()
        if 'mse' in loss_name:
            base_loss_fn = nn.MSELoss()
        elif 'bce' in loss_name:
            base_loss_fn = nn.BCEWithLogitsLoss()
        elif 'ce' in loss_name:
            base_loss_fn = nn.CrossEntropyLoss()
        else:
            raise NotImplementedError(f"Unsupported loss: {self.loss}")

        # --- 是否叠加 TV ---
        use_tv = '+tv' in loss_name
        lambda_tv = getattr(self, 'lambda_tv', 0.00875)
        tv_type = getattr(self, 'tv_type', 'charb').lower()

        if tv_type == 'aniso':
            tv_fn = tv_loss_aniso
        elif tv_type == 'iso':
            tv_fn = tv_loss_iso
        else:
            tv_fn = tv_loss_charbonnier  # 默认 Charbonnier

        # class perceptual_loss(nn.Module):
        #     """
        #     多层加权感知损失（默认使用 relu1_2 / relu2_2 / relu3_4）。
        #     可与像素/对抗损失组合：total = lambda_p * P + lambda_l1 * L1 + ...
        #     """
        #
        #     def __init__(self,
        #                  layers=("relu1_2", "relu2_2", "relu3_4"),
        #                  layer_weights={"relu1_2": 1.0, "relu2_2": 1.0, "relu3_4": 1.0},
        #                  criterion="l1"):
        #         super().__init__()
        #         self.feat_net = TruncatedVGG19_UpToRelu34(return_layers=layers)
        #         self.layers = layers
        #         self.layer_weights = layer_weights
        #         if criterion == "l1":
        #             self.crit = F.l1_loss
        #         elif criterion == "l2":
        #             self.crit = F.mse_loss
        #         else:
        #             raise ValueError("criterion must be 'l1' or 'l2'")
        #
        #     def forward(self, pred, target):
        #         # pred/target: [N,1,H,W] 或 [N,3,H,W]，值域任意（内部会标准化处理）
        #         # 重要：不要对 feat_net 反向；默认已冻结参数，只对 pred 传播梯度
        #         with torch.no_grad():
        #             feat_t = self.feat_net(target)
        #         feat_p = self.feat_net(pred)  # 这里不加 no_grad，以便对 pred 反向
        #
        #         loss = 0.0
        #         for name in self.layers:
        #             w = self.layer_weights.get(name, 1.0)
        #             loss = loss + w * self.crit(feat_p[name], feat_t[name])
        #         return loss

        class perceptual_loss(nn.Module):
            def __init__(
                    self,
                    layers=("relu2_2", "relu3_4", "relu4_4"),
                    layer_weights={"relu2_2": 1.0, "relu3_4": 0.5, "relu4_4": 0.05},
                    criterion="l2",
                    normalize_features=True,
            ):
                super().__init__()
                self.features = VGGFeatureExtractor(layers)
                self.layers = layers
                self.layer_weights = layer_weights
                self.normalize_features = normalize_features

                if criterion == "l2":
                    self.crit = nn.MSELoss()
                elif criterion == "l1":
                    self.crit = nn.L1Loss()
                else:
                    raise ValueError("criterion should be 'l1' or 'l2'")

            def forward(self, pred, target):

                # ----(1) 单通道 → 3通道 ----
                if pred.shape[1] == 1:
                    pred = pred.repeat(1, 3, 1, 1)
                if target.shape[1] == 1:
                    target = target.repeat(1, 3, 1, 1)

                # ----(2) 限定为 [0,1] 区间 ----
                pred = torch.clamp(pred, 0, 1)
                target = torch.clamp(target, 0, 1)

                # ----(3) 提取 VGG 特征 ----
                feat_p = self.features(pred)
                feat_t = self.features(target)

                loss = 0.0
                for name in self.layers:
                    fp = feat_p[name]
                    ft = feat_t[name]

                    # ----(4) 特征归一化（稳定训练）----
                    if self.normalize_features:
                        fp = fp / (fp.norm(p=2, dim=1, keepdim=True) + 1e-8)
                        ft = ft / (ft.norm(p=2, dim=1, keepdim=True) + 1e-8)

                    # ----(5) L2/L1 损失 ----
                    layer_loss = self.crit(fp, ft)
                    loss += self.layer_weights[name] * layer_loss

                return loss

        use_per = ('+per' in loss_name)
        lambda_per = 0.25

        if use_per:
            perceptual_loss_model = perceptual_loss().to(self.device)
            perceptual_loss_model.eval()  # 冻结梯度计算
            for p in perceptual_loss_model.parameters():
                p.requires_grad_(False)

            # 封装函数接口
            def perceptual_loss_fn(pred, target):
                return perceptual_loss_model(pred, target)
        else:
            perceptual_loss_fn = None
        self.loss_meter = LossMeter()
        # --- 组合损失：保持签名 (pred, target) ---
        def combined_loss(pred, target):
            base = base_loss_fn(pred, target)
            # loss_total = base
            # if use_tv:
            #     loss_total += lambda_tv * tv_fn(pred)
            # if use_per:
            #     loss_total += lambda_per * perceptual_loss_fn(pred, target)
            # return loss_total
            loss_tv = lambda_tv * tv_fn(pred) if use_tv else 0.
            loss_per = lambda_per * perceptual_loss_fn(pred, target) if use_per else 0.
            self.loss_meter.update(base.item(),
                                   float(loss_tv),
                                   float(loss_per),
                                   n=8)
            loss_total = base + loss_tv + loss_per
            return loss_total
        return combined_loss

    def _get_optimizer(self, model):
        if self.optimizer == 'adam':
            optimizer = torch.optim.Adam(model.parameters(), lr=self.lr)
            # optimizer = torch.optim.Adam(model.parameters(), lr=self.lr, weight_decay = 1e-4)
        elif self.optimizer == 'sgd':
            optimizer = torch.optim.SGD(model.parameters(), lr=self.lr, momentum=0.9)
        elif self.optimizer == 'adamW':
            optimizer = torch.optim.AdamW(model.parameters(), lr=self.lr)
        else:
            raise NotImplementedError("Unsupported optimizer: {}".format(self.optimizer))

        optimizer.param_groups[0]['lr'] = self.lr
        # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            optimizer,
            T_max=self.epochs,  # 学习率衰减的总周期（等于总epoch数，最后一个epoch LR→0）
            eta_min=1e-6  # 最小学习率（避免衰减到0导致数值不稳定，设1e-8即可）
        )
        # 或者换成 CosineAnnealingLR / ReduceLROnPlateau
        return optimizer, scheduler
        # return optimizer



    # def _save_train_reconstructed_image(self, recon, x_true, y, epoch, iter_num, save_dir=None):
    #     """保存重构图像和真实图像"""
    #     recon = recon[3, 0].detach()  # [H,W], float
    #     x_true = x_true[3, 0].detach()
    #     y = y[3, 0].detach().cpu()
    #     psnr_recon = compute_psnr(recon, x_true)
    #     recon_np = recon.cpu().numpy()
    #     xtrue_np = x_true.cpu().numpy()
    #     ssim_recon = ssim_metric(xtrue_np, recon_np, data_range=1.0)
    #
    #     recon = (np.clip(recon_np, 0, 1) * 255.0 + 0.5).astype(np.uint8)
    #     x_true = (np.clip(xtrue_np, 0, 1) * 255.0 + 0.5).astype(np.uint8)
    #     y = (np.clip(y.numpy(), 0, 1) * 255.0 + 0.5).astype(np.uint8)
    #
    #     # 创建图像保存路径
    #     # save_path = os.path.join(self.img_save_dir, 'invSigmak_mse_batch=8_segUnet_lr=0.005_numworkers2_init=10', f"epoch_{epoch}_iter_{iter_num}")
    #     if save_dir is None:
    #         # 原先行为： self.img_save_dir + 固定子目录 + epoch_iter
    #         save_path = os.path.join(self.img_save_dir, 'mse+tv+per_train840x10x4_val_split0.2_batch=8_lr=0.005_numworkers4_init=10M3FD_snr45_tv1e-4_per1e-3','train',
    #                                  f"epoch_{epoch}_iter_{iter_num}")
    #     else:
    #         save_path = save_dir
    #
    #     os.makedirs(save_path, exist_ok=True)
    #
    #     # 绘制并保存重构图像
    #     plt.figure(figsize=(12, 4))
    #
    #     plt.subplot(1, 3, 1)
    #     plt.imshow(x_true, cmap='gray')
    #     plt.title('True Image')
    #     plt.axis('off')
    #     plt.savefig(os.path.join(save_path, 'true.png'))
    #
    #     plt.subplot(1, 3, 2)
    #     plt.imshow(y, cmap='gray')
    #     plt.title('Observed (LR)')
    #     plt.axis('off')
    #     plt.savefig(os.path.join(save_path, 'LR.png'))
    #
    #     plt.subplot(1, 3, 3)
    #     plt.imshow(recon, cmap='gray')
    #     plt.title(f'Reconstructed\nPSNR={psnr_recon:.2f} dB  SSIM={ssim_recon:.4f}')
    #     plt.axis('off')
    #     plt.savefig(os.path.join(save_path, 'reconstructed.png'))
    #
    #     plt.tight_layout()  # 调整子图间距
    #     plt.savefig(os.path.join(save_path, 'comparison.png'))
    #     plt.close()

    # def _save_val_reconstructed_image(self, recon, x_true, y, epoch, iter_num, save_dir=None):
    #     if not hasattr(self, 'best_psnr'):
    #         self.best_psnr = -1
    #     if not hasattr(self, 'best_ssim'):
    #         self.best_ssim = -1
    #     """保存重构图像和真实图像"""
    #     recon = recon[3, 0].detach()  # [H,W], float
    #     x_true = x_true[3, 0].detach()
    #     y = y[3, 0].detach().cpu()
    #     psnr_recon = compute_psnr(recon, x_true)
    #     recon_np = recon.cpu().numpy()
    #     xtrue_np = x_true.cpu().numpy()
    #     ssim_recon = ssim_metric(xtrue_np, recon_np, data_range=1.0)
    #     if psnr_recon <= self.best_psnr and ssim_recon <= self.best_ssim:
    #         return
    #
    #     recon = (np.clip(recon_np, 0, 1) * 255.0 + 0.5).astype(np.uint8)
    #     x_true = (np.clip(xtrue_np, 0, 1) * 255.0 + 0.5).astype(np.uint8)
    #     y = (np.clip(y.numpy(), 0, 1) * 255.0 + 0.5).astype(np.uint8)
    #
    #     # 创建图像保存路径
    #     # save_path = os.path.join(self.img_save_dir, 'invSigmak_mse_batch=8_segUnet_lr=0.005_numworkers2_init=10', f"epoch_{epoch}_iter_{iter_num}")
    #     if save_dir is None:
    #         # 原先行为： self.img_save_dir + 固定子目录 + epoch_iter
    #         save_path = os.path.join(self.img_save_dir, 'mse+tv+per_train840x10x4_val_split0.2_batch=8_lr=0.005_numworkers4_init=10M3FD_snr45_tv1e-4_per1e-3', 'val',
    #                                 f"epoch_{epoch}_iter_{iter_num}")
    #     else:
    #         save_path = save_dir
    #
    #     os.makedirs(save_path, exist_ok=True)
    #
    #     # 绘制并保存重构图像
    #     plt.figure(figsize=(12, 4))
    #
    #     plt.subplot(1, 3, 1)
    #     plt.imshow(x_true, cmap='gray')
    #     plt.title('True Image')
    #     plt.axis('off')
    #     plt.savefig(os.path.join(save_path, 'true.png'))
    #
    #     plt.subplot(1, 3, 2)
    #     plt.imshow(y, cmap='gray')
    #     plt.title('Observed (LR)')
    #     plt.axis('off')
    #     plt.savefig(os.path.join(save_path, 'LR.png'))
    #
    #     plt.subplot(1, 3, 3)
    #     plt.imshow(recon, cmap='gray')
    #     plt.title(f'Reconstructed\nPSNR={psnr_recon:.2f} dB  SSIM={ssim_recon:.4f}')
    #     plt.axis('off')
    #     plt.savefig(os.path.join(save_path, 'reconstructed.png'))
    #
    #     plt.tight_layout()  # 调整子图间距
    #     plt.savefig(os.path.join(save_path, 'comparison.png'))
    #     plt.close()

    # def save_model(self, model= None, save_path=None):
    #     """保存当前训练的模型参数"""
    #     model_to_save = model if model is not None else self.model
    #     if not isinstance(model_to_save, torch.nn.Module):
    #         raise TypeError(f"model_to_save should be nn.Module, got {type(model_to_save)}")
    #     if save_path is None:
    #         save_dir = os.path.join(self.img_save_dir, "saved_models")
    #         os.makedirs(save_dir, exist_ok=True)
    #         save_path = os.path.join(save_dir, "mse+tv+per_train840x10x4_val_split0.2_ln_lr0.005_M3FD_snr45_tv1e-4_per1e-3.pth")
    #     torch.save(model.state_dict(), save_path)
    #     print(f"[INFO] 模型已保存至 {save_path}")
    #     return save_path
    # def save_best_train_model(self, train_psnr, model= None):
    #     """根据验证 PSNR 保存最优模型"""
    #     if train_psnr > self.best_train_psnr:
    #         self.best_train_psnr = train_psnr
    #         save_dir = os.path.join(self.img_save_dir, 'mse_bicubic_split0.2_batch=8_lr=2e-4_numworkers4_init=10M3FD','models')
    #         os.makedirs(save_dir, exist_ok=True)
    #         self.best_model_path = os.path.join(save_dir, "best_train_model.pth")
    #         torch.save(model.state_dict(), self.best_model_path)
    #         print(f"[INFO] 发现更优模型，保存为 best_train_model.pth  (PSNR={train_psnr:.4f})")


    def save_best_val_model(self, val_psnr, model= None):
        """根据验证 PSNR 保存最优模型"""
        if val_psnr > self.best_val_psnr:
            self.best_val_psnr = val_psnr
            save_dir = os.path.join(self.img_save_dir, 'mse+0.00875tv+0.25per_bicubic_lr=1e-4_M3FD_4Res+UNet2_relu2_2 1.0,relu3_4 0.5,relu4_4 0.05','models')
            os.makedirs(save_dir, exist_ok=True)
            self.best_model_path = os.path.join(save_dir, "best_val_model.pth")
            torch.save(model.state_dict(), self.best_model_path)
            print(f"[INFO] 发现更优模型，保存为 best_val_model.pth  (PSNR={val_psnr:.4f})")

    def training(self, writer):
        # train_dataset, val_dataset = self._get_dataset()
        print("Load dataset...")
        train_dataset, val_dataset = self._get_train_val_datasets(val_ratio=0.2)
        # print("Dataset size:", len(dataset))
        train_loader = DataLoader(train_dataset,
                          batch_size=self.batch_size,
                          shuffle=True,
                          num_workers=self.num_workers,
                          pin_memory=True)
        val_loader = DataLoader(val_dataset,
                                batch_size=self.batch_size,
                                shuffle=False,
                                num_workers=self.num_workers,
                                pin_memory=True)
        loss_func = self._get_loss_func()
        model = self._get_model()
        optimizer, scheduler = self._get_optimizer(model)
        # optimizer = self._get_optimizer(model)

        print("Start training...")
        # losses, psnrs, ssims = [], [], []
        train_losses, train_psnrs, train_ssims = [], [], []
        train_base_losses, train_tv_losses, train_per_losses = [], [], []
        # train_base_losses, train_per_losses = [], []
        val_losses, val_psnrs, val_ssims = [], [], []

        def plot_three_loss_curves(epoch_list,
                                   base_losses, tv_losses, per_losses,
                                   save_path):
            plt.figure(figsize=(12, 4))

            plt.subplot(1, 3, 1)
            plt.plot(epoch_list, base_losses, marker='o', label='Base Loss')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title('Base Loss')
            plt.grid(True)
            plt.legend()

            plt.subplot(1, 3, 2)
            plt.plot(epoch_list, tv_losses, marker='s', label='TV Loss', color='g')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title('TV Loss')
            plt.grid(True)
            plt.legend()

            plt.subplot(1, 3, 3)
            plt.plot(epoch_list, per_losses, marker='^', label='Perceptual Loss', color='r')
            plt.xlabel('Epoch')
            plt.ylabel('Loss')
            plt.title('Perceptual Loss')
            plt.grid(True)
            plt.legend()

            plt.tight_layout()
            plt.savefig(save_path)
            plt.close()
            print(f"[INFO] Loss curves saved to {save_path}")

        def plot_progress(epoch,
                          train_losses, train_psnrs, train_ssims,
                          val_losses, val_psnrs, val_ssims):
            epochs = range(1, epoch + 1)
            plt.figure(figsize=(15, 4))
            """保存到当前 epoch 为止的曲线"""
            # -------- Loss --------
            plt.subplot(1, 3, 1)
            plt.plot(epochs, train_losses[:epoch], marker='o', label='Train Loss')
            plt.plot(epochs, val_losses[:epoch], marker='o', label='Val Loss')
            plt.title('Loss')
            plt.xlabel('Epoch')
            # plt.ylim(0, 10)
            plt.grid(True)
            plt.legend()

            # -------- PSNR --------
            plt.subplot(1, 3, 2)
            plt.plot(epochs, train_psnrs[:epoch], marker='o', label='Train PSNR')
            plt.plot(epochs, val_psnrs[:epoch], marker='o', label='Val PSNR')
            plt.title('PSNR')
            plt.xlabel('Epoch')
            plt.ylim(0, 40)
            plt.grid(True)
            plt.legend()

            # -------- SSIM --------
            plt.subplot(1, 3, 3)
            plt.plot(epochs, train_ssims[:epoch], marker='o', label='Train SSIM')
            plt.plot(epochs, val_ssims[:epoch], marker='o', label='Val SSIM')
            plt.title('SSIM')
            plt.xlabel('Epoch')
            plt.ylim(0, 1)
            plt.grid(True)
            plt.legend()

            plt.tight_layout()
            save_dir = os.path.join(self.img_save_dir, 'mse+0.00875tv+0.25per_bicubic_lr=1e-4_M3FD_4Res+UNet2_relu2_2 1.0,relu3_4 0.5,relu4_4 0.05')
            os.makedirs(save_dir, exist_ok=True)
            save_path = os.path.join(save_dir, f"progress_epoch_{epoch}.png")
            plt.savefig(save_path)
            plt.close()
            print(f"[INFO] 保存训练曲线到 {save_path}")

        for epoch in range(self.epochs):
            model.train()
            train_loss = 0
            train_psnr, train_ssim = 0, 0
            count = 0
            self.loss_meter.reset()
            # Training
            # for iter_num, data in enumerate(test_loader):
            loop = tqdm(enumerate(train_loader), total=len(train_loader), desc=f"Epoch {epoch + 1}/{self.epochs}")
            for iter_num, (x_true, y, Aty, idxs) in loop:
                x_true = x_true.to(self.device, non_blocking=True)  # [B,1,H,W]
                y = y.to(self.device, non_blocking=True)  # [B,1,H/scale,W/scale]
                Aty = Aty.to(self.device, non_blocking=True)
                diagAtA_np = np.load(".\diagAtA_gaussian.npy")
                mk_0 = F.interpolate(y, scale_factor=4, mode='bicubic', align_corners=False)
                mk = mk_0
                mk_1 = mk_0
                invSigmak_1, invSigmak, lambdak = self.initialization(Aty)
                diagAtA = torch.from_numpy(diagAtA_np)
                diagAtA = torch.clamp(diagAtA, min=0.0)
                diagAtA = diagAtA.to(self.device)
                # print("diagAtA:", diagAtA.min(), diagAtA.max(), diagAtA.mean().item())
                output = model(Aty, diagAtA, mk_1, invSigmak_1, mk, invSigmak, lambdak)
                recon = output[2]

                for i in range(recon.shape[0]):
                    recon_t = recon[i, 0].detach()
                    hr_t = x_true[i, 0].detach()
                    psnr_train = compute_psnr(recon_t, hr_t)
                    recon_np_i = recon_t.cpu().numpy()  # 仅单个样本转 CPU，开销小
                    hr_np_i = hr_t.cpu().numpy()
                    ssim_train = structural_similarity(hr_np_i, recon_np_i, data_range=1.0)
                    train_psnr += psnr_train
                    train_ssim += ssim_train
                    count += 1
                # if iter_num == 0:
                #     self._save_train_reconstructed_image(recon, x_true, y, epoch, iter_num)

                loss = loss_func(output[2], x_true)
                # print('\n Loss Epoch {} : {:.4f}\n'.format(epoch, loss))
                train_loss += loss.item()
                loop.set_postfix({
                    "Loss": f"{loss.item():.4f}",
                    "Last PSNR": f"{psnr_train:.2f}dB",
                    "Last SSIM": f"{ssim_train:.4f}"
                })
                loss.backward()

                if iter_num % self.log_interval == 0:
                    optimizer.step()
                    optimizer.zero_grad()


            scheduler.step()
            mean_base, mean_tv, mean_per = self.loss_meter.report()
            train_base_losses.append(mean_base)
            train_tv_losses.append(mean_tv)
            train_per_losses.append(mean_per)
            print(f"[Epoch {epoch}] MeanLoss: base={mean_base:.6f}, tv={mean_tv:.6f}, per={mean_per:.6f}")
            # print(f"[Epoch {epoch}] MeanLoss: base={mean_base:.6f}, per={mean_per:.6f}")
            avg_train_loss = train_loss / len(train_loader)
            avg_train_psnr = train_psnr / count
            avg_train_ssim = train_ssim / count
            # self.save_best_train_model(avg_train_psnr, model=model)
            # 保存到历史
            train_losses.append(avg_train_loss)
            train_psnrs.append(avg_train_psnr)
            train_ssims.append(avg_train_ssim)
            avg_val_loss, avg_val_psnr, avg_val_ssim = \
            self.validate(model, val_loader, val_dataset, epoch)
            val_losses.append(avg_val_loss)
            val_psnrs.append(avg_val_psnr)
            val_ssims.append(avg_val_ssim)
            self.save_best_val_model(avg_val_psnr, model=model)
            # 打印并保存模型/画图
            print(
                f'Epoch {epoch}: Train Loss={avg_train_loss:.4f}, Train PSNR={avg_train_psnr:.2f}, Train SSIM={avg_train_ssim:.4f}')
            print(f'[VAL] Loss={avg_val_loss:.4f} PSNR={avg_val_psnr:.2f} SSIM={avg_val_ssim:.4f}\n')
            # self.save_model(model=model)

            epoch_list = list(range(1, len(train_base_losses) + 1))
            plot_progress(epoch,
                          train_losses, train_psnrs, train_ssims,
                          val_losses, val_psnrs, val_ssims)
            save_dir = os.path.join(self.img_save_dir,
                                    'mse+0.00875tv+0.25per_bicubic_lr=1e-4_M3FD_4Res+UNet2_relu2_2 1.0,relu3_4 0.5,relu4_4 0.05')
            os.makedirs(save_dir, exist_ok=True)
            save_path = os.path.join(save_dir, "train_loss_components.png")
            plot_three_loss_curves(epoch_list,
                                   train_base_losses,
                                   train_tv_losses,
                                   train_per_losses,
                                   save_path)


            # ---------------------------
            # VALIDATION
            # ---------------------------
    def validate(self,model, val_loader, val_dataset, epoch):
        model.eval()
        val_loss = 0.0
        val_psnr = 0.0
        val_ssim = 0.0
        val_count = 0
        loss_func = self._get_loss_func()
        device = self.device
        with torch.no_grad():
            val_loop = tqdm(enumerate(val_loader),
                            total=len(val_loader),
                            desc=f"Valid {epoch + 1}/{self.epochs}")
            for iter_num, (x_true, y, Aty, idxs) in val_loop:
                x_true = x_true.to(self.device, non_blocking=True)
                x_true = x_true.to(self.device, non_blocking=True)  # [B,1,H,W]
                y = y.to(self.device, non_blocking=True)  # [B,1,H/scale,W/scale]
                Aty = Aty.to(self.device, non_blocking=True)
                diagAtA_np = np.load(".\diagAtA_gaussian.npy")
                diagAtA = torch.from_numpy(diagAtA_np).clamp(min=0).to(device)

                mk_0 = F.interpolate(y, scale_factor=4, mode='bicubic', align_corners=False)
                mk_1 = mk_0
                mk = mk_0

                invSigmak_1, invSigmak, lambdak = self.initialization(Aty)
                output = model(Aty, diagAtA, mk_1, invSigmak_1, mk, invSigmak, lambdak)
                recon = output[2]

                v_loss = loss_func(recon, x_true)
                val_loss += v_loss.item()

                for b in range(recon.shape[0]):
                    recon_t = recon[b, 0].detach()
                    hr_t = x_true[b, 0].detach()
                    psnr_val = compute_psnr(recon_t, hr_t)
                    ssim_val = structural_similarity(hr_t.cpu().numpy(), recon_t.cpu().numpy(), data_range=1.0)
                    val_psnr += psnr_val
                    val_ssim += ssim_val
                    val_count += 1
                val_loop.set_postfix({
                    "Val Loss": f"{v_loss.item():.4f}",
                    "Last PSNR": f"{psnr_val:.2f}dB",
                    "Last SSIM": f"{ssim_val:.4f}"
                })

                # if iter_num == 0:
                #     self._save_val_reconstructed_image(recon, x_true, y, epoch, iter_num)

        avg_val_loss = val_loss / len(val_loader)
        avg_val_psnr = val_psnr / val_count
        avg_val_ssim = val_ssim / val_count
        return avg_val_loss, avg_val_psnr, avg_val_ssim


        # torch.save(model.state_dict(), './output/final.ckpt')
                # pred = output.argmax(dim=1, keepdim=True)
                # train_correct = pred.eq(target.view_as(pred)).sum().item()

            # # Performance metrics
            # metrics_dict = compute_metrics(model, val_loader, loss_func, self.device)
            # print('-' * 10, ' Epoch {} Iteration {} '.format(epoch, iter_num), '-' * 10, )
            # print("Accuracy \t {:.3f}".format(metrics_dict['Accuracy']))
            # print("Sensitivity \t {:.3f}".format(metrics_dict['Sensitivity']))
            # print("Specificity \t {:.3f}".format(metrics_dict['Specificity']))
            # print("Area Under ROC \t {:.3f}".format(metrics_dict['Roc_score']))
            # print("Val Loss \t {}".format(metrics_dict["Validation Loss"]))
            # print('-' * 40, )

            # # save model with the best validation accuracy
            # if metrics_dict['Accuracy'] > best_val_score:
            #     torch.save(model, "best_model.pkl")
            #     best_val_score = metrics_dict['Accuracy']

            # print the metrics for training data for the epoch
            # print('\nTraining Performance Epoch {}: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\n'.format(
            #     epoch, train_loss / len(train_loader.dataset), train_correct, len(train_loader.dataset),
            #            100.0 * train_correct / len(train_loader.dataset)))
            #
            # # log the accuracy and losses in tensorboard
            # writer.add_scalars("Losses", {'Train loss': train_loss / len(train_loader),
            #                               'Validation_loss': metrics_dict["Validation Loss"]},
            #                    epoch)
            # writer.add_scalars("Accuracies", {"Train Accuracy": 100.0 * train_correct / len(train_loader.dataset),
            #                                   "Valid Accuracy": 100.0 * metrics_dict["Accuracy"]}, epoch)

            # Add data to the EarlyStopper object
            # early_stopper.add_data(model, metrics_dict['Validation Loss'], metrics_dict['Accuracy'])

            # If both accuracy and loss are not improving, stop the training
            # if early_stopper.stop() == 1:
            #     break

            # if only loss is not improving, lower the learning rate
            # if early_stopper.stop() == 3:
            #     for param_group in optimizer.param_groups:
            #         self.lr *= 0.1
            #         param_group['lr'] = self.lr
            #         print('Updating the learning rate to {}'.format(self.lr))
            #         early_stopper.reset()
    # def test(self):

    # def evaluate(model, test_loader):

    def initialization(self, mk_0):
        invSigmak_1 = 10 * torch.ones(mk_0.shape).to(self.device)
        invSigmak = 10 * torch.ones(mk_0.shape).to(self.device)


        # operators
        Dhx = lambda x: x - torch.roll(x, 1, dims=3)
        Dvx = lambda x: x - torch.roll(x, 1, dims=2)
        lambdak = (torch.square(Dhx(mk_0)) + torch.square(Dvx(mk_0)) + torch.tensor(1e-10)).to(self.device)
        return invSigmak_1, invSigmak, lambdak

"""# Main"""

def main():
    print("Directory: " + os.getcwd())
    # args = get_arguments()
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    args= Args(device=device, moddir="./models", outdir='./outputs',
                logdir='./logs', imgdir='./images', resdir='./results', initdir='./inits',
                num_classes=2, model='UnrollVBA', lr=1e-4, optimizer='adam',
                dataset='infrared', batch_size=8, epochs=200, train_size=1.0,
                num_workers=4, loss='mse+tv+per', log_interval=8)
    # args = get_arguments()
    # 数据集路径

    log_dir = "./logs"
    writer = SummaryWriter(log_dir)

    trainer = Trainer(args)
    trainer.training(writer)

if __name__ == "__main__":
    main()